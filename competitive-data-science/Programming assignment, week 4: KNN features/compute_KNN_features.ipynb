{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 1.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will need to implement features, based on nearest neighbours. \n",
    "\n",
    "KNN classifier (regressor) is a very powerful model, when the features are homogeneous and it is a very common practice to use KNN as first level model. In this homework we will extend KNN model and compute more features, based on nearest neighbors and their distances. \n",
    "\n",
    "You will need to implement a number of features, that were one of the key features, that leaded the instructors to prizes in [Otto](https://www.kaggle.com/c/otto-group-product-classification-challenge) and [Springleaf](https://www.kaggle.com/c/springleaf-marketing-response) competitions. Of course, the list of features you will need to implement can be extended, in fact in competitions the list was at least 3 times larger. So when solving a real competition do not hesitate to make up your own features.   \n",
    "\n",
    "You can optionally implement multicore feature computation. Nearest neighbours are hard to compute so it is preferable to have a parallel version of the algorithm. In fact, it is really a cool skill to know how to use `multiprocessing`, `joblib` and etc. In this homework you will have a chance to see the benefits of parallel algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check your versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions we use here are not present in old versions of the libraries, so make sure you have up-to-date software. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.13.3\n",
      "pandas 0.21.0\n",
      "sklearn 0.19.1\n",
      "scipy 0.19.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import scipy.sparse \n",
    "\n",
    "for p in [np, pd, sklearn, scipy]:\n",
    "    print (p.__name__, p.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The versions should be not less than:\n",
    "\n",
    "    numpy 1.13.1\n",
    "    pandas 0.20.3\n",
    "    sklearn 0.19.0\n",
    "    scipy 0.19.1\n",
    "   \n",
    "**IMPORTANT!** The results with `scipy=1.0.0` will be different! Make sure you use _exactly_ version `0.19.1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn features and labels. These features are actually OOF predictions of linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../readonly/KNN_features_data/X.npz'\n",
    "train_labels = '../readonly/KNN_features_data/Y.npy'\n",
    "\n",
    "test_path = '../readonly/KNN_features_data/X_test.npz'\n",
    "test_labels = '../readonly/KNN_features_data/Y_test.npy'\n",
    "\n",
    "# Train data\n",
    "X = scipy.sparse.load_npz(train_path)\n",
    "Y = np.load(train_labels)\n",
    "\n",
    "# Test data\n",
    "X_test = scipy.sparse.load_npz(test_path)\n",
    "Y_test = np.load(test_labels)\n",
    "\n",
    "# Out-of-fold features we loaded above were generated with n_splits=4 and skf seed 123\n",
    "# So it is better to use seed 123 for generating KNN features as well \n",
    "skf_seed = 123\n",
    "n_splits = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you need to implement features, based on nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NearestNeighborsFeats(BaseEstimator, ClassifierMixin):\n",
    "    '''\n",
    "        This class should implement KNN features extraction \n",
    "    '''\n",
    "    def __init__(self, n_jobs, k_list, metric, n_classes=None, n_neighbors=None, eps=1e-6):\n",
    "        self.n_jobs = n_jobs\n",
    "        self.k_list = k_list\n",
    "        self.metric = metric\n",
    "        \n",
    "        if n_neighbors is None:\n",
    "            self.n_neighbors = max(k_list) \n",
    "        else:\n",
    "            self.n_neighbors = n_neighbors\n",
    "            \n",
    "        self.eps = eps        \n",
    "        self.n_classes_ = n_classes\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "            Set's up the train set and self.NN object\n",
    "        '''\n",
    "        # Create a NearestNeighbors (NN) object. We will use it in `predict` function \n",
    "        self.NN = NearestNeighbors(n_neighbors=max(self.k_list), \n",
    "                                      metric=self.metric, \n",
    "                                      n_jobs=1, \n",
    "                                      algorithm='brute' if self.metric=='cosine' else 'auto')\n",
    "        self.NN.fit(X)\n",
    "        \n",
    "        # Store labels \n",
    "        self.y_train = y\n",
    "        \n",
    "        # Save how many classes we have\n",
    "        self.n_classes = np.unique(y).shape[0] if self.n_classes_ is None else self.n_classes_\n",
    "        \n",
    "        \n",
    "    def predict(self, X):       \n",
    "        '''\n",
    "            Produces KNN features for every object of a dataset X\n",
    "        '''\n",
    "        if self.n_jobs == 1:\n",
    "            test_feats = []\n",
    "            for i in range(X.shape[0]):\n",
    "                test_feats.append(self.get_features_for_one(X[i:i+1]))\n",
    "        else:\n",
    "            '''\n",
    "                 *Make it parallel*\n",
    "                     Number of threads should be controlled by `self.n_jobs`  \n",
    "                     \n",
    "                     \n",
    "                     You can use whatever you want to do it\n",
    "                     For Python 3 the simplest option would be to use \n",
    "                     `multiprocessing.Pool` (but don't use `multiprocessing.dummy.Pool` here)\n",
    "                     You may try use `joblib` but you will most likely encounter an error, \n",
    "                     that you will need to google up (and eventually it will work slowly)\n",
    "                     \n",
    "                     For Python 2 I also suggest using `multiprocessing.Pool` \n",
    "                     You will need to use a hint from this blog \n",
    "                     http://qingkaikong.blogspot.ru/2016/12/python-parallel-method-in-class.html\n",
    "                     I could not get `joblib` working at all for this code \n",
    "                     (but in general `joblib` is very convenient)\n",
    "                     \n",
    "            '''\n",
    "            \n",
    "            # YOUR CODE GOES HERE\n",
    "            p = Pool(processes=self.n_jobs)\n",
    "            test_feats = p.map(self.get_features_for_one,[X[i:i+1] for i in range(X.shape[0])])\n",
    "            # test_feats =  # YOUR CODE GOES HERE\n",
    "            # YOUR CODE GOES HERE\n",
    "            \n",
    "            #assert False, 'You need to implement it for n_jobs > 1'\n",
    "            \n",
    "            \n",
    "            \n",
    "        return np.vstack(test_feats)\n",
    "        \n",
    "        \n",
    "    def get_features_for_one(self, x):\n",
    "        '''\n",
    "            Computes KNN features for a single object `x`\n",
    "        '''\n",
    "\n",
    "        NN_output = self.NN.kneighbors(x)\n",
    "        \n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores indices of the neighbors\n",
    "        neighs = NN_output[1][0]\n",
    "        \n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores distances to corresponding neighbors\n",
    "        neighs_dist = NN_output[0][0] \n",
    "\n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores labels of corresponding neighbors\n",
    "        neighs_y = self.y_train[neighs] \n",
    " \n",
    "        \n",
    "        ## ========================================== ##\n",
    "        ##              YOUR CODE BELOW\n",
    "        ## ========================================== ##\n",
    "        \n",
    "        # We will accumulate the computed features here\n",
    "        # Eventually it will be a list of lists or np.arrays\n",
    "        # and we will use np.hstack to concatenate those\n",
    "        return_list = [] \n",
    "        \n",
    "        \n",
    "        ''' \n",
    "            1. Fraction of objects of every class.\n",
    "               It is basically a KNNÐ¡lassifiers predictions.\n",
    "\n",
    "               Take a look at `np.bincount` function, it can be very helpful\n",
    "               Note that the values should sum up to one\n",
    "        '''\n",
    "       \n",
    "        for k in self.k_list:\n",
    "            #CODE\n",
    "            feats = np.bincount(neighs_y[:k],minlength=self.n_classes)\n",
    "            \n",
    "            feats  = feats / feats.sum()\n",
    "            \n",
    "            assert len(feats) == self.n_classes\n",
    "            return_list += [feats]\n",
    "        \n",
    "        \n",
    "        '''\n",
    "            2. Same label streak: the largest number N, \n",
    "               such that N nearest neighbors have the same label.\n",
    "               \n",
    "               What can help you: `np.where`\n",
    "        '''\n",
    "        #CODE\n",
    "#         if (neighs_y != neighs_y[0]).astype(int).sum() > 0:\n",
    "#             feats = np.where(np.cumsum((neighs_y != neighs_y[0]).astype(int)) == 1)[0][0]\n",
    "#         else:\n",
    "#             feats = len(neighs_y)\n",
    "\n",
    "\n",
    "        diffs=np.insert(np.diff(neighs_y),0,999)\n",
    "\n",
    "        feats=np.unique(neighs_y[diffs==0],return_counts=True)[1].max()+1\n",
    "            \n",
    "        feats=[feats]       \n",
    "        \n",
    "        assert len(feats) == 1\n",
    "        return_list += [feats]\n",
    "        \n",
    "        '''\n",
    "            3. Minimum distance to objects of each class\n",
    "               Find the first instance of a class and take its distance as features.\n",
    "               \n",
    "               If there are no neighboring objects of some classes, \n",
    "               Then set distance to that class to be 999.\n",
    "\n",
    "               `np.where` might be helpful\n",
    "        '''\n",
    "        feats = [neighs_dist[neighs_y == i][0] if (neighs_y == i).sum() > 0 else 999 for i in range(self.n_classes)]\n",
    "\n",
    "        assert len(feats) == self.n_classes\n",
    "        return_list += [feats]\n",
    "        \n",
    "        '''\n",
    "            4. Minimum *normalized* distance to objects of each class\n",
    "               As 3. but we normalize (divide) the distances\n",
    "               by the distance to the closest neighbor.\n",
    "               \n",
    "               If there are no neighboring objects of some classes, \n",
    "               Then set distance to that class to be 999.\n",
    "               \n",
    "               Do not forget to add self.eps to denominator.\n",
    "        '''\n",
    "        feats = []\n",
    "        for i in range(self.n_classes):\n",
    "            # CODE\n",
    "            feat = neighs_dist[neighs_y == i][0] if (neighs_y == i).sum() > 0 else 999\n",
    "            feats.append(feat / (self.eps + neighs_dist[0]))\n",
    "        assert len(feats) == self.n_classes\n",
    "        return_list += [feats]\n",
    "        \n",
    "        '''\n",
    "            5. \n",
    "               5.1 Distance to Kth neighbor\n",
    "                   Think of this as of quantiles of a distribution\n",
    "               5.2 Distance to Kth neighbor normalized by \n",
    "                   distance to the first neighbor\n",
    "               \n",
    "               feat_51, feat_52 are answers to 5.1. and 5.2.\n",
    "               should be scalars\n",
    "               \n",
    "               Do not forget to add self.eps to denominator.\n",
    "        '''\n",
    "        for k in self.k_list:\n",
    "            \n",
    "            feat_51 = neighs_dist[k-1] \n",
    "            feat_52 = neighs_dist[k-1] / (neighs_dist[0] + self.eps) \n",
    "            return_list += [[feat_51, feat_52]]\n",
    "        \n",
    "        '''\n",
    "            6. Mean distance to neighbors of each class for each K from `k_list` \n",
    "                   For each class select the neighbors of that class among K nearest neighbors \n",
    "                   and compute the average distance to those objects\n",
    "                   \n",
    "                   If there are no objects of a certain class among K neighbors, set mean distance to 999\n",
    "                   \n",
    "               You can use `np.bincount` with appropriate weights\n",
    "               Don't forget, that if you divide by something, \n",
    "               You need to add `self.eps` to denominator.\n",
    "        '''\n",
    "        for k in self.k_list:\n",
    "            \n",
    "            numerator = np.zeros(self.n_classes)\n",
    "            denominator = np.full(self.n_classes, self.eps)\n",
    "            t = neighs_y[:k].max() + 1\n",
    "            numerator[:t] = np.bincount(neighs_y[:k], weights=neighs_dist[:k])\n",
    "            denominator[:t] = self.eps + np.bincount(neighs_y[:k])\n",
    "            feats = np.where(numerator>0, numerator/denominator, 999)\n",
    "            \n",
    "            assert len(feats) == self.n_classes\n",
    "            return_list += [feats]\n",
    "        \n",
    "        \n",
    "        # merge\n",
    "        knn_feats = np.hstack(return_list)\n",
    "        \n",
    "        assert knn_feats.shape == (239,) or knn_feats.shape == (239, 1)\n",
    "        return knn_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure you've implemented everything correctly we provide you the correct features for the first 50 objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviation from ground thruth features: 107909255926.180252\n",
      "There is a problem in feature 0, which is a part of section 1.\n",
      "There is a problem in feature 1, which is a part of section 1.\n",
      "There is a problem in feature 3, which is a part of section 1.\n",
      "There is a problem in feature 4, which is a part of section 1.\n",
      "There is a problem in feature 6, which is a part of section 1.\n",
      "There is a problem in feature 7, which is a part of section 1.\n",
      "There is a problem in feature 8, which is a part of section 1.\n",
      "There is a problem in feature 10, which is a part of section 1.\n",
      "There is a problem in feature 12, which is a part of section 1.\n",
      "There is a problem in feature 13, which is a part of section 1.\n",
      "There is a problem in feature 14, which is a part of section 1.\n",
      "There is a problem in feature 15, which is a part of section 1.\n",
      "There is a problem in feature 17, which is a part of section 1.\n",
      "There is a problem in feature 18, which is a part of section 1.\n",
      "There is a problem in feature 19, which is a part of section 1.\n",
      "There is a problem in feature 21, which is a part of section 1.\n",
      "There is a problem in feature 22, which is a part of section 1.\n",
      "There is a problem in feature 24, which is a part of section 1.\n",
      "There is a problem in feature 26, which is a part of section 1.\n",
      "There is a problem in feature 27, which is a part of section 1.\n",
      "There is a problem in feature 28, which is a part of section 1.\n",
      "There is a problem in feature 29, which is a part of section 1.\n",
      "There is a problem in feature 30, which is a part of section 1.\n",
      "There is a problem in feature 32, which is a part of section 1.\n",
      "There is a problem in feature 33, which is a part of section 1.\n",
      "There is a problem in feature 35, which is a part of section 1.\n",
      "There is a problem in feature 36, which is a part of section 1.\n",
      "There is a problem in feature 37, which is a part of section 1.\n",
      "There is a problem in feature 39, which is a part of section 1.\n",
      "There is a problem in feature 40, which is a part of section 1.\n",
      "There is a problem in feature 41, which is a part of section 1.\n",
      "There is a problem in feature 42, which is a part of section 1.\n",
      "There is a problem in feature 43, which is a part of section 1.\n",
      "There is a problem in feature 44, which is a part of section 1.\n",
      "There is a problem in feature 46, which is a part of section 1.\n",
      "There is a problem in feature 47, which is a part of section 1.\n",
      "There is a problem in feature 48, which is a part of section 1.\n",
      "There is a problem in feature 50, which is a part of section 1.\n",
      "There is a problem in feature 51, which is a part of section 1.\n",
      "There is a problem in feature 52, which is a part of section 1.\n",
      "There is a problem in feature 53, which is a part of section 1.\n",
      "There is a problem in feature 55, which is a part of section 1.\n",
      "There is a problem in feature 56, which is a part of section 1.\n",
      "There is a problem in feature 57, which is a part of section 1.\n",
      "There is a problem in feature 58, which is a part of section 1.\n",
      "There is a problem in feature 59, which is a part of section 1.\n",
      "There is a problem in feature 60, which is a part of section 1.\n",
      "There is a problem in feature 61, which is a part of section 1.\n",
      "There is a problem in feature 62, which is a part of section 1.\n",
      "There is a problem in feature 64, which is a part of section 1.\n",
      "There is a problem in feature 65, which is a part of section 1.\n",
      "There is a problem in feature 66, which is a part of section 1.\n",
      "There is a problem in feature 67, which is a part of section 1.\n",
      "There is a problem in feature 68, which is a part of section 1.\n",
      "There is a problem in feature 69, which is a part of section 1.\n",
      "There is a problem in feature 70, which is a part of section 1.\n",
      "There is a problem in feature 71, which is a part of section 1.\n",
      "There is a problem in feature 72, which is a part of section 1.\n",
      "There is a problem in feature 73, which is a part of section 1.\n",
      "There is a problem in feature 74, which is a part of section 1.\n",
      "There is a problem in feature 75, which is a part of section 1.\n",
      "There is a problem in feature 76, which is a part of section 1.\n",
      "There is a problem in feature 77, which is a part of section 1.\n",
      "There is a problem in feature 79, which is a part of section 1.\n",
      "There is a problem in feature 80, which is a part of section 1.\n",
      "There is a problem in feature 81, which is a part of section 1.\n",
      "There is a problem in feature 82, which is a part of section 1.\n",
      "There is a problem in feature 83, which is a part of section 1.\n",
      "There is a problem in feature 84, which is a part of section 1.\n",
      "There is a problem in feature 85, which is a part of section 1.\n",
      "There is a problem in feature 86, which is a part of section 1.\n",
      "There is a problem in feature 87, which is a part of section 2.\n",
      "There is a problem in feature 88, which is a part of section 3.\n",
      "There is a problem in feature 89, which is a part of section 3.\n",
      "There is a problem in feature 90, which is a part of section 3.\n",
      "There is a problem in feature 91, which is a part of section 3.\n",
      "There is a problem in feature 92, which is a part of section 3.\n",
      "There is a problem in feature 94, which is a part of section 3.\n",
      "There is a problem in feature 95, which is a part of section 3.\n",
      "There is a problem in feature 96, which is a part of section 3.\n",
      "There is a problem in feature 97, which is a part of section 3.\n",
      "There is a problem in feature 98, which is a part of section 3.\n",
      "There is a problem in feature 99, which is a part of section 3.\n",
      "There is a problem in feature 100, which is a part of section 3.\n",
      "There is a problem in feature 101, which is a part of section 3.\n",
      "There is a problem in feature 102, which is a part of section 3.\n",
      "There is a problem in feature 103, which is a part of section 3.\n",
      "There is a problem in feature 104, which is a part of section 3.\n",
      "There is a problem in feature 105, which is a part of section 3.\n",
      "There is a problem in feature 106, which is a part of section 3.\n",
      "There is a problem in feature 107, which is a part of section 3.\n",
      "There is a problem in feature 109, which is a part of section 3.\n",
      "There is a problem in feature 110, which is a part of section 3.\n",
      "There is a problem in feature 111, which is a part of section 3.\n",
      "There is a problem in feature 112, which is a part of section 3.\n",
      "There is a problem in feature 113, which is a part of section 3.\n",
      "There is a problem in feature 114, which is a part of section 3.\n",
      "There is a problem in feature 115, which is a part of section 3.\n",
      "There is a problem in feature 116, which is a part of section 3.\n",
      "There is a problem in feature 117, which is a part of section 4.\n",
      "There is a problem in feature 118, which is a part of section 4.\n",
      "There is a problem in feature 119, which is a part of section 4.\n",
      "There is a problem in feature 120, which is a part of section 4.\n",
      "There is a problem in feature 121, which is a part of section 4.\n",
      "There is a problem in feature 122, which is a part of section 4.\n",
      "There is a problem in feature 123, which is a part of section 4.\n",
      "There is a problem in feature 124, which is a part of section 4.\n",
      "There is a problem in feature 125, which is a part of section 4.\n",
      "There is a problem in feature 126, which is a part of section 4.\n",
      "There is a problem in feature 127, which is a part of section 4.\n",
      "There is a problem in feature 128, which is a part of section 4.\n",
      "There is a problem in feature 129, which is a part of section 4.\n",
      "There is a problem in feature 130, which is a part of section 4.\n",
      "There is a problem in feature 131, which is a part of section 4.\n",
      "There is a problem in feature 132, which is a part of section 4.\n",
      "There is a problem in feature 133, which is a part of section 4.\n",
      "There is a problem in feature 134, which is a part of section 4.\n",
      "There is a problem in feature 135, which is a part of section 4.\n",
      "There is a problem in feature 136, which is a part of section 4.\n",
      "There is a problem in feature 137, which is a part of section 4.\n",
      "There is a problem in feature 138, which is a part of section 4.\n",
      "There is a problem in feature 139, which is a part of section 4.\n",
      "There is a problem in feature 140, which is a part of section 4.\n",
      "There is a problem in feature 141, which is a part of section 4.\n",
      "There is a problem in feature 142, which is a part of section 4.\n",
      "There is a problem in feature 143, which is a part of section 4.\n",
      "There is a problem in feature 144, which is a part of section 4.\n",
      "There is a problem in feature 145, which is a part of section 4.\n",
      "There is a problem in feature 146, which is a part of section 5.\n",
      "There is a problem in feature 147, which is a part of section 5.\n",
      "There is a problem in feature 148, which is a part of section 5.\n",
      "There is a problem in feature 149, which is a part of section 5.\n",
      "There is a problem in feature 150, which is a part of section 5.\n",
      "There is a problem in feature 151, which is a part of section 5.\n",
      "There is a problem in feature 152, which is a part of section 6.\n",
      "There is a problem in feature 153, which is a part of section 6.\n",
      "There is a problem in feature 155, which is a part of section 6.\n",
      "There is a problem in feature 156, which is a part of section 6.\n",
      "There is a problem in feature 158, which is a part of section 6.\n",
      "There is a problem in feature 159, which is a part of section 6.\n",
      "There is a problem in feature 160, which is a part of section 6.\n",
      "There is a problem in feature 162, which is a part of section 6.\n",
      "There is a problem in feature 164, which is a part of section 6.\n",
      "There is a problem in feature 165, which is a part of section 6.\n",
      "There is a problem in feature 166, which is a part of section 6.\n",
      "There is a problem in feature 167, which is a part of section 6.\n",
      "There is a problem in feature 169, which is a part of section 6.\n",
      "There is a problem in feature 170, which is a part of section 6.\n",
      "There is a problem in feature 171, which is a part of section 6.\n",
      "There is a problem in feature 173, which is a part of section 6.\n",
      "There is a problem in feature 174, which is a part of section 6.\n",
      "There is a problem in feature 176, which is a part of section 6.\n",
      "There is a problem in feature 178, which is a part of section 6.\n",
      "There is a problem in feature 179, which is a part of section 6.\n",
      "There is a problem in feature 180, which is a part of section 6.\n",
      "There is a problem in feature 181, which is a part of section 6.\n",
      "There is a problem in feature 182, which is a part of section 6.\n",
      "There is a problem in feature 184, which is a part of section 6.\n",
      "There is a problem in feature 185, which is a part of section 6.\n",
      "There is a problem in feature 187, which is a part of section 6.\n",
      "There is a problem in feature 188, which is a part of section 6.\n",
      "There is a problem in feature 189, which is a part of section 6.\n",
      "There is a problem in feature 191, which is a part of section 6.\n",
      "There is a problem in feature 192, which is a part of section 6.\n",
      "There is a problem in feature 193, which is a part of section 6.\n",
      "There is a problem in feature 194, which is a part of section 6.\n",
      "There is a problem in feature 195, which is a part of section 6.\n",
      "There is a problem in feature 196, which is a part of section 6.\n",
      "There is a problem in feature 198, which is a part of section 6.\n",
      "There is a problem in feature 199, which is a part of section 6.\n",
      "There is a problem in feature 200, which is a part of section 6.\n",
      "There is a problem in feature 202, which is a part of section 6.\n",
      "There is a problem in feature 203, which is a part of section 6.\n",
      "There is a problem in feature 204, which is a part of section 6.\n",
      "There is a problem in feature 205, which is a part of section 6.\n",
      "There is a problem in feature 207, which is a part of section 6.\n",
      "There is a problem in feature 208, which is a part of section 6.\n",
      "There is a problem in feature 209, which is a part of section 6.\n",
      "There is a problem in feature 210, which is a part of section 6.\n",
      "There is a problem in feature 211, which is a part of section 6.\n",
      "There is a problem in feature 212, which is a part of section 6.\n",
      "There is a problem in feature 213, which is a part of section 6.\n",
      "There is a problem in feature 214, which is a part of section 6.\n",
      "There is a problem in feature 216, which is a part of section 6.\n",
      "There is a problem in feature 217, which is a part of section 6.\n",
      "There is a problem in feature 218, which is a part of section 6.\n",
      "There is a problem in feature 219, which is a part of section 6.\n",
      "There is a problem in feature 220, which is a part of section 6.\n",
      "There is a problem in feature 221, which is a part of section 6.\n",
      "There is a problem in feature 222, which is a part of section 6.\n",
      "There is a problem in feature 223, which is a part of section 6.\n",
      "There is a problem in feature 224, which is a part of section 6.\n",
      "There is a problem in feature 225, which is a part of section 6.\n",
      "There is a problem in feature 226, which is a part of section 6.\n",
      "There is a problem in feature 227, which is a part of section 6.\n",
      "There is a problem in feature 228, which is a part of section 6.\n",
      "There is a problem in feature 229, which is a part of section 6.\n",
      "There is a problem in feature 231, which is a part of section 6.\n",
      "There is a problem in feature 232, which is a part of section 6.\n",
      "There is a problem in feature 233, which is a part of section 6.\n",
      "There is a problem in feature 234, which is a part of section 6.\n",
      "There is a problem in feature 235, which is a part of section 6.\n",
      "There is a problem in feature 236, which is a part of section 6.\n",
      "There is a problem in feature 237, which is a part of section 6.\n",
      "There is a problem in feature 238, which is a part of section 6.\n"
     ]
    }
   ],
   "source": [
    "# a list of K in KNN, starts with one \n",
    "k_list = [3, 8, 32]\n",
    "#k_list=[1,2,3]\n",
    "# Load correct features\n",
    "true_knn_feats_first50 = np.load('../readonly/KNN_features_data/knn_feats_test_first50.npy')\n",
    "\n",
    "# Create instance of our KNN feature extractor\n",
    "NNF = NearestNeighborsFeats(n_jobs=1, k_list=k_list, metric='minkowski')\n",
    "\n",
    "# Fit on train set\n",
    "#NNF.fit(X[:5], Y[:5])\n",
    "NNF.fit(X, Y)\n",
    "# Get features for test\n",
    "test_knn_feats = NNF.predict(X_test[:50])\n",
    "#test_knn_feats = NNF.predict(X_test[1])\n",
    "\n",
    "# This should be zero\n",
    "print ('Deviation from ground thruth features: %f' % np.abs(test_knn_feats - true_knn_feats_first50[44:45]).sum())\n",
    "\n",
    "deviation =np.abs(test_knn_feats - true_knn_feats_first50[44:45]).sum(0)\n",
    "for m in np.where(deviation > 1e-3)[0]: \n",
    "    p = np.where(np.array([87, 88, 117, 146, 152, 239]) > m)[0][0]\n",
    "    print ('There is a problem in feature %d, which is a part of section %d.' % (m, p + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviation from ground thruth features: 107892211710.110199\n"
     ]
    }
   ],
   "source": [
    "print ('Deviation from ground thruth features: %f' % np.abs(test_knn_feats - true_knn_feats_first50[44:45]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement parallel computations and compute features for the train and test sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features for test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute features for the whole test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minkowski\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-13-515ee704124d>\", line 149, in get_features_for_one\n    feats=np.unique(neighs_y[diffs==0],return_counts=True)[1].max()+1\n  File \"/home/jose/scratch/venv/lib/python3.6/site-packages/numpy/core/_methods.py\", line 26, in _amax\n    return umr_maximum(a, axis, None, out, keepdims)\nValueError: zero-size array to reduction operation maximum which has no identity\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-45559489d89e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Get features for test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtest_knn_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNNF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Dump the features to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-515ee704124d>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m# YOUR CODE GOES HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mtest_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features_for_one\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;31m# test_feats =  # YOUR CODE GOES HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;31m# YOUR CODE GOES HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "for metric in ['minkowski', 'cosine']:\n",
    "    print (metric)\n",
    "    \n",
    "    # Create instance of our KNN feature extractor\n",
    "    NNF = NearestNeighborsFeats(n_jobs=4, k_list=k_list, metric=metric)\n",
    "    \n",
    "    # Fit on train set\n",
    "    NNF.fit(X, Y)\n",
    "\n",
    "    # Get features for test\n",
    "    test_knn_feats = NNF.predict(X_test)\n",
    "    \n",
    "    # Dump the features to disk\n",
    "    np.save('data/knn_feats_%s_test.npy' % metric , test_knn_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features for train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute features for train, using out-of-fold strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differently from other homework we will not implement OOF predictions ourselves\n",
    "# but use sklearn's `cross_val_predict`\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# We will use two metrics for KNN\n",
    "for metric in ['minkowski', 'cosine']:\n",
    "    print (metric)\n",
    "    \n",
    "    # Set up splitting scheme, use StratifiedKFold\n",
    "    # use skf_seed and n_splits defined above with shuffle=True\n",
    "    skf = # YOUR CODE GOES HERE\n",
    "    \n",
    "    # Create instance of our KNN feature extractor\n",
    "    # n_jobs can be larger than the number of cores\n",
    "    NNF = NearestNeighborsFeats(n_jobs=4, k_list=k_list, metric=metric)\n",
    "    \n",
    "    # Get KNN features using OOF use cross_val_predict with right parameters\n",
    "    preds = # YOUR CODE GOES HERE\n",
    "    \n",
    "    # Save the features\n",
    "    np.save('data/knn_feats_%s_train.npy' % metric, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you made the above cells work, just run the following cell to produce a number to submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for metric in ['minkowski', 'cosine']:\n",
    "    knn_feats_train = np.load('data/knn_feats_%s_train.npy' % metric)\n",
    "    knn_feats_test = np.load('data/knn_feats_%s_test.npy' % metric)\n",
    "    \n",
    "    s += knn_feats_train.mean() + knn_feats_test.mean()\n",
    "    \n",
    "answer = np.floor(s)\n",
    "print (answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grader import Grader\n",
    "\n",
    "grader.submit_tag('statistic', answer)\n",
    "\n",
    "STUDENT_EMAIL = # EMAIL HERE\n",
    "STUDENT_TOKEN = # TOKEN HERE\n",
    "grader.status()\n",
    "\n",
    "grader.submit(STUDENT_EMAIL, STUDENT_TOKEN)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
