{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your very own neural network\n",
    "\n",
    "In this notebook, we're going to build a neural network using naught but pure numpy and steel nerves. It's going to be fun, I promise!\n",
    "\n",
    "![img](https://s27.postimg.org/vpui4r5n7/cartoon-2029952_960_720.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here goes our main class: a layer that can .forward() and .backward()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \"\"\"\n",
    "    A building block. Each layer is capable of performing two things:\n",
    "    \n",
    "    - Process input to get output:           output = layer.forward(input)\n",
    "    \n",
    "    - Propagate gradients through itself:    grad_input = layer.backward(input, grad_output)\n",
    "    \n",
    "    Some layers also have learnable parameters which they update during layer.backward.\n",
    "    \"\"\"\n",
    "    def __init__ (self):\n",
    "        \"\"\"Here you can initialize layer parameters (if any) and auxiliary stuff.\"\"\"\n",
    "        # A dummy layer does nothing\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Takes input data of shape [batch, input_units], returns output data [batch, output_units]\n",
    "        \"\"\"\n",
    "        # A dummy layer just returns whatever it gets as input.\n",
    "        return input\n",
    "\n",
    "    def backward(self,input, grad_output):\n",
    "        \"\"\"\n",
    "        Performs a backpropagation step through the layer, with respect to the given input.\n",
    "        \n",
    "        To compute loss gradients w.r.t input, you need to apply chain rule (backprop):\n",
    "        \n",
    "        d loss / d x  = (d loss / d layer) * (d layer / d x)\n",
    "        \n",
    "        Luckily, you already receive d loss / d layer as input, so you only need to multiply it by d layer / d x.\n",
    "        \n",
    "        If your layer has parameters (e.g. dense layer), you also need to update them here using d loss / d layer\n",
    "        \"\"\"\n",
    "        # The gradient of a dummy layer is precisely grad_output, but we'll write it more explicitly\n",
    "        num_units = input.shape[1]\n",
    "        \n",
    "        d_layer_d_input = np.eye(num_units)\n",
    "        \n",
    "        return np.dot(grad_output, d_layer_d_input) # chain rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The road ahead\n",
    "\n",
    "We're going to build a neural network that classifies MNIST digits. To do so, we'll need a few building blocks:\n",
    "- Dense layer - a fully-connected layer, $f(X)=W \\cdot X + \\vec{b}$\n",
    "- ReLU layer (or any other nonlinearity you want)\n",
    "- Loss function - crossentropy\n",
    "- Backprop algorithm - a stochastic gradient descent with backpropageted gradients\n",
    "\n",
    "Let's approach them one at a time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinearity layer\n",
    "\n",
    "This is the simplest layer you can get: it simply applies a nonlinearity to each element of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "    def __init__(self):\n",
    "        \"\"\"ReLU layer simply applies elementwise rectified linear unit to all inputs\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"Apply elementwise ReLU to [batch, input_units] matrix\"\"\"\n",
    "        return np.maximum(input,0)\n",
    "\n",
    "    \n",
    "    def backward(self, input, grad_output):\n",
    "        \"\"\"Compute gradient of loss w.r.t. ReLU input\"\"\"\n",
    "        relu_grad = input > 0\n",
    "        return grad_output*relu_grad        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 32)\n",
      "(10, 32)\n"
     ]
    }
   ],
   "source": [
    "# some tests\n",
    "from util import eval_numerical_gradient\n",
    "x = np.linspace(-1,1,10*32).reshape([10,32])\n",
    "l = ReLU()\n",
    "grads = l.backward(x,np.ones([10,32])/(32*10))\n",
    "numeric_grads = eval_numerical_gradient(lambda x: l.forward(x).mean(), x=x)\n",
    "print(grads.shape)\n",
    "print(numeric_grads.shape)\n",
    "assert np.allclose(grads, numeric_grads, rtol=1e-3, atol=0),\\\n",
    "    \"gradient returned by your layer does not match the numerically computed gradient\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instant primer: lambda functions\n",
    "\n",
    "In python, you can define functions in one line using the `lambda` syntax: `lambda param1, param2: expression`\n",
    "\n",
    "For example: `f = lambda x, y: x+y` is equivalent to a normal function:\n",
    "\n",
    "```\n",
    "def f(x,y):\n",
    "    return x+y\n",
    "```\n",
    "For more information, click [here](http://www.secnetix.de/olli/Python/lambda_functions.hawk).    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense layer\n",
    "\n",
    "Now let's build something more complicated. Unlike nonlinearity, a dense layer actually has something to learn.\n",
    "\n",
    "A dense layer applies affine transformation. In a vectorized form, it can be described as:\n",
    "$$f(X)= W \\cdot X + \\vec b $$\n",
    "\n",
    "Where \n",
    "* X is an object-feature matrix of shape [batch_size,num_features],\n",
    "* W is a weight matrix [batch_size,num_outputs] \n",
    "* and b is a vector of num_outputs biases.\n",
    "\n",
    "Both W and b are initialized during layer creation and updated each time backward is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_units, output_units, learning_rate=0.1):\n",
    "        \"\"\"\n",
    "        A dense layer is a layer which performs a learned affine transformation:\n",
    "        f(x) = <W*x> + b\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # initialize weights with small random numbers. We use normal initialization, \n",
    "        # but surely there is something better. Try this once you got it working: http://bit.ly/2vTlmaJ\n",
    "\n",
    "        self.weights = np.random.randn(input_units, output_units)*0.01\n",
    "\n",
    "        self.biases = np.zeros(output_units)\n",
    "        \n",
    "    def forward(self,input):\n",
    "        \"\"\"\n",
    "        Perform an affine transformation:\n",
    "        f(x) = <W*x> + b\n",
    "        \n",
    "        input shape: [batch, input_units]\n",
    "        output shape: [batch, output units]\n",
    "        \"\"\"\n",
    "        return np.dot(input,self.weights)+self.biases\n",
    "    \n",
    "    def backward(self,input,grad_output,verbose=False):\n",
    "  \n",
    "        # compute d f / d x = d f / d dense * d dense / d x\n",
    "        # where d dense/ d x = weights transposed\n",
    "\n",
    "       \n",
    "        grad_input=np.dot(grad_output,self.weights.transpose())\n",
    "        grad_biases = grad_output.mean(axis=0)\n",
    "   \n",
    "        dfddense=grad_output\n",
    "    #.mean(axis=0,keepdims=True)\n",
    "      \n",
    "        ddensedw=input.T\n",
    "        #.mean(axis=0,keepdims=True).transpose()\n",
    "        grad_weights=np.dot(ddensedw,dfddense)/input.shape[0]\n",
    "        #.mean(axis=0)         \n",
    "        \n",
    "      \n",
    "                \n",
    "        assert grad_weights.shape == self.weights.shape and grad_biases.shape == self.biases.shape\n",
    "        # Here we perform a stochastic gradient descent step. \n",
    "        # Later on, you can try replacing that with something better.\n",
    "        self.weights = self.weights - self.learning_rate*grad_weights\n",
    "        self.biases = self.biases - self.learning_rate*grad_biases\n",
    "        \n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the dense layer\n",
    "\n",
    "Here we have a few tests to make sure your dense layer works properly. You can just run them, get 3 \"well done\"s and forget they ever existed.\n",
    "\n",
    "... or not get 3 \"well done\"s and go fix stuff. If that is the case, here are some tips for you:\n",
    "* Make sure you compute gradients for W and b as __mean gradient over batch__, not sums of gradients.\n",
    "* If you're debugging, try saving gradients in class fields, like \"self.grad_w = grad_w\" or print first 3-5 weights. This helps debugging.\n",
    "* If nothing else helps, try ignoring tests and proceed to network training. If it trains alright, you may be off by something that does not affect network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n",
      "(2, 4)\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "l = Dense(128, 150)\n",
    "\n",
    "assert -0.05 < l.weights.mean() < 0.05 and 1e-3 < l.weights.std() < 1e-1,\\\n",
    "    \"The initial weights must have zero mean and small variance. \"\\\n",
    "    \"If you know what you're doing, remove this assertion.\"\n",
    "assert -0.05 < l.biases.mean() < 0.05, \"Biases must be zero mean. Ignore if you have a reason to do otherwise.\"\n",
    "\n",
    "# To test the outputs, we explicitly set weights with fixed values. DO NOT DO THAT IN ACTUAL NETWORK!\n",
    "l = Dense(3,4)\n",
    "\n",
    "x = np.linspace(-1,1,2*3).reshape([2,3])\n",
    "l.weights = np.linspace(-1,1,3*4).reshape([3,4])\n",
    "l.biases = np.linspace(-1,1,4)\n",
    "print(l.forward(x).shape)\n",
    "print(np.array([[ 0.07272727,  0.41212121,  0.75151515,  1.09090909],\n",
    "                                          [-0.90909091,  0.08484848,  1.07878788,  2.07272727]]).shape)\n",
    "    \n",
    "assert np.allclose(l.forward(x),np.array([[ 0.07272727,  0.41212121,  0.75151515,  1.09090909],\n",
    "                                          [-0.90909091,  0.08484848,  1.07878788,  2.07272727]]))\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 77)\n",
      "(10, 77)\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# To test the grads, we use gradients obtained via finite differences\n",
    "\n",
    "from util import eval_numerical_gradient\n",
    "\n",
    "x = np.linspace(-1,1,10*77).reshape([10,77])\n",
    "x=np.ones_like(x)\n",
    "l = Dense(77,64,learning_rate=0)\n",
    "\n",
    "numeric_grads = eval_numerical_gradient(lambda x: l.forward(x).sum(),x)\n",
    "grads = l.backward(x,np.ones([10,64]))\n",
    "print(numeric_grads.shape)\n",
    "print(grads.shape)\n",
    "assert np.allclose(grads,numeric_grads,rtol=1e-3,atol=0), \"input gradient does not match numeric grad\"\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64) (32, 64)\n",
      "(64,) (64,)\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# Test the gradients w.r.t. params\n",
    "def compute_out_given_wb(w,b):\n",
    "    l = Dense(32,64,learning_rate=1)\n",
    "    l.weights = np.array(w)\n",
    "    l.biases = np.array(b)\n",
    "    x = np.linspace(-1,1,10*32).reshape([10,32])\n",
    "    return l.forward(x)\n",
    "    \n",
    "def compute_grad_by_params(w,b):\n",
    "    l = Dense(32,64,learning_rate=1)\n",
    "    l.weights = np.array(w)\n",
    "    l.biases = np.array(b)\n",
    "    x = np.linspace(-1,1,10*32).reshape([10,32])\n",
    "    l.backward(x,np.ones([10,64]))\n",
    "    return w - l.weights, b - l.biases\n",
    "    \n",
    "w,b = np.random.randn(32,64), np.linspace(-1,1,64)\n",
    "\n",
    "numeric_dw = eval_numerical_gradient(lambda w: compute_out_given_wb(w,b).mean(0).sum(),w )\n",
    "numeric_db = eval_numerical_gradient(lambda b: compute_out_given_wb(w,b).mean(0).sum(),b )\n",
    "grad_w,grad_b = compute_grad_by_params(w,b)\n",
    "print(numeric_dw.shape,grad_w.shape)\n",
    "print(numeric_db.shape,grad_b.shape)\n",
    "\n",
    "assert np.allclose(numeric_dw,grad_w,rtol=1e-3,atol=0), \"weight gradient does not match numeric weight gradient\"\n",
    "assert np.allclose(numeric_db,grad_b,rtol=1e-3,atol=0), \"weight gradient does not match numeric weight gradient\"\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The loss function\n",
    "\n",
    "Since we want to predict probabilities, it would be logical for us to define softmax nonlinearity on top of our network and compute loss given predicted probabilities. However, there is a better way to do so.\n",
    "\n",
    "If you write down the expression for crossentropy as a function of softmax logits (a), you'll see:\n",
    "\n",
    "$$ loss = - log \\space {e^{a_{correct}} \\over {\\underset i \\sum e^{a_i} } } $$\n",
    "\n",
    "If you take a closer look, ya'll see that it can be rewritten as:\n",
    "\n",
    "$$ loss = - a_{correct} + log {\\underset i \\sum e^{a_i} } $$\n",
    "\n",
    "It's called Log-softmax and it's better than naive log(softmax(a)) in all aspects:\n",
    "* Better numerical stability\n",
    "* Easier to get derivative right\n",
    "* Marginally faster to compute\n",
    "\n",
    "So why not just use log-softmax throughout our computation and never actually bother to estimate probabilities.\n",
    "\n",
    "Here you are! We've defined the both loss functions for you so that you could focus on neural network part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_crossentropy_with_logits(logits,reference_answers):\n",
    "    \"\"\"Compute crossentropy from logits[batch, n_classes] and ids of correct answers\"\"\"\n",
    "    logits_for_answers = logits[np.arange(len(logits)),reference_answers]\n",
    "    \n",
    "    xentropy = - logits_for_answers + np.log(np.sum(np.exp(logits),axis=-1))\n",
    "    \n",
    "    return xentropy\n",
    "\n",
    "def grad_softmax_crossentropy_with_logits(logits,reference_answers):\n",
    "    \"\"\"Compute crossentropy gradient from logits[batch, n_classes] and ids of correct answers\"\"\"\n",
    "    ones_for_answers = np.zeros_like(logits)\n",
    "    ones_for_answers[np.arange(len(logits)),reference_answers] = 1\n",
    "    \n",
    "    softmax = np.exp(logits) / np.exp(logits).sum(axis=-1,keepdims=True)\n",
    "    \n",
    "    return - ones_for_answers + softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 10)\n",
      "(50, 10)\n"
     ]
    }
   ],
   "source": [
    "logits = np.linspace(-1,1,500).reshape([50,10])\n",
    "answers = np.arange(50)%10\n",
    "\n",
    "#softmax_crossentropy_with_logits(logits,answers)\n",
    "grads = grad_softmax_crossentropy_with_logits(logits,answers)\n",
    "numeric_grads = eval_numerical_gradient(lambda l: softmax_crossentropy_with_logits(l,answers).sum(),logits)\n",
    "print(grads.shape)\n",
    "print(numeric_grads.shape)\n",
    "assert np.allclose(numeric_grads, grads, rtol=1e-3, atol=0),\\\n",
    "    \"The reference implementation has just failed. That is bizzare.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full network\n",
    "\n",
    "Now let's combine what we've just built into a working neural network. As we announced, we're gonna use this monster to classify handwritten digits, so let's get them loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAF1CAYAAADx1LGMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc9a96f7cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from preprocessed_mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset(flatten=True)\n",
    "\n",
    "plt.figure(figsize=[6,6])\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.title(\"Label: %i\"%y_train[i])\n",
    "    plt.imshow(X_train[i].reshape([28,28]),cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define network as a list of layers, each applied on top of previous one. In this setting, computing predictions and training becomes trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = []\n",
    "network.append(Dense(X_train.shape[1],100))\n",
    "network.append(ReLU())\n",
    "network.append(Dense(100,200))\n",
    "network.append(ReLU())\n",
    "network.append(Dense(200,10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(network, X):\n",
    "    \"\"\"\n",
    "    Compute activations of all network layers by applying them sequentially.\n",
    "    Return a list of activations for each layer. \n",
    "    Make sure last activation corresponds to network logits.\n",
    "    \"\"\"\n",
    "    activations = []\n",
    "    input = X\n",
    " \n",
    "    for i,layer in enumerate(network):\n",
    "        if i==0:\n",
    "            activations.append(layer.forward(input))\n",
    "        else:\n",
    "            activations.append(layer.forward(activations[i-1]))           \n",
    "\n",
    "\n",
    "#     x=np.zeros_like(activations[-1])\n",
    "#     x[activations[-1]==np.amax(activations[-1],axis=1,keepdims=True)]=1\n",
    "    \n",
    "    assert len(activations) == len(network)\n",
    "    return activations\n",
    "\n",
    "def predict(network,X):\n",
    "    \"\"\"\n",
    "    Compute network predictions.\n",
    "    \"\"\"\n",
    "    logits = forward(network,X)[-1]\n",
    "    return logits.argmax(axis=-1)\n",
    "\n",
    "def train(network,X,y):\n",
    "    \"\"\"\n",
    "    Train your network on a given batch of X and y.\n",
    "    You first need to run forward to get all layer activations.\n",
    "    Then you can run layer.backward going from last to first layer.\n",
    "    \n",
    "    After you called backward for all layers, all Dense layers have already made one gradient step.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the layer activations\n",
    "    layer_activations = forward(network,X)\n",
    "    layer_inputs = [X]+layer_activations  #layer_input[i] is an input for network[i]\n",
    "    logits = layer_activations[-1]\n",
    "    \n",
    "    # Compute the loss and the initial gradient\n",
    "    loss = softmax_crossentropy_with_logits(logits,y)\n",
    "    loss_grad = grad_softmax_crossentropy_with_logits(logits,y)\n",
    "    \n",
    "    # We start at the end, as we know the gradient\n",
    "    reverse_inputs=layer_inputs[::-1]\n",
    "    reverse_network=network[::-1]\n",
    "    gradient=loss_grad\n",
    "    for i,layer in enumerate(reverse_network):\n",
    "                 \n",
    "        gradient=layer.backward(reverse_inputs[i+1],gradient)        \n",
    "        \n",
    "    return np.mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of tests, we provide you with a training loop that prints training and validation accuracies on every epoch.\n",
    "\n",
    "If your implementation of forward and backward are correct, your accuracy should grow from 90~93% to >97% with the default network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "As usual, we split data into minibatches, feed each such minibatch into the network and update weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(len(inputs))\n",
    "    for start_idx in trange(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "train_log = []\n",
    "val_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n",
      "Train accuracy: 0.9916\n",
      "Val accuracy: 0.9763\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc968274dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 514/3125 [00:01<00:07, 327.24it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-570d9e17bee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtrain_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-bd507f901b0a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(network, X, y)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-7e5587aace3e>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, input, grad_output, verbose)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mddensedw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m#.mean(axis=0,keepdims=True).transpose()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mgrad_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddensedw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdfddense\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;31m#.mean(axis=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('error')\n",
    "    for epoch in range(150):\n",
    "\n",
    "        for x_batch,y_batch in iterate_minibatches(X_train,y_train,batchsize=16,shuffle=True):\n",
    "            train(network,x_batch,y_batch)\n",
    "\n",
    "        train_log.append(np.mean(predict(network,X_train)==y_train))\n",
    "        val_log.append(np.mean(predict(network,X_val)==y_val))\n",
    "\n",
    "        clear_output()\n",
    "        print(\"Epoch\",epoch)\n",
    "        print(\"Train accuracy:\",train_log[-1])\n",
    "        print(\"Val accuracy:\",val_log[-1])\n",
    "        plt.plot(train_log,label='train accuracy')\n",
    "        plt.plot(val_log,label='val accuracy')\n",
    "        plt.legend(loc='best')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer-reviewed assignment\n",
    "\n",
    "Congradulations, you managed to get this far! There is just one quest left undone, and this time you'll get to choose what to do.\n",
    "\n",
    "\n",
    "#### Option I: initialization\n",
    "* Implement Dense layer with Xavier initialization as explained [here](http://bit.ly/2vTlmaJ)\n",
    "\n",
    "To pass this assignment, you must conduct an experiment showing how xavier initialization compares to default initialization on deep networks (5+ layers).\n",
    "\n",
    "\n",
    "#### Option II: regularization\n",
    "* Implement a version of Dense layer with L2 regularization penalty: when updating Dense Layer weights, adjust gradients to minimize\n",
    "\n",
    "$$ Loss = Crossentropy + \\alpha \\cdot \\underset i \\sum {w_i}^2 $$\n",
    "\n",
    "To pass this assignment, you must conduct an experiment showing if regularization mitigates overfitting in case of abundantly large number of neurons. Consider tuning $\\alpha$ for better results.\n",
    "\n",
    "#### Option III: optimization\n",
    "* Implement a version of Dense layer that uses momentum/rmsprop or whatever method worked best for you last time.\n",
    "\n",
    "Most of those methods require persistent parameters like momentum direction or moving average grad norm, but you can easily store those params inside your layers.\n",
    "\n",
    "To pass this assignment, you must conduct an experiment showing how your chosen method performs compared to vanilla SGD.\n",
    "\n",
    "### General remarks\n",
    "_Please read the peer-review guidelines before starting this part of the assignment._\n",
    "\n",
    "In short, a good solution is one that:\n",
    "* is based on this notebook\n",
    "* runs in the default course environment with Run All\n",
    "* its code doesn't cause spontaneous eye bleeding\n",
    "* its report is easy to read.\n",
    "\n",
    "_Formally we can't ban you from writing boring reports, but if you bored your reviewer to death, there's noone left alive to give you the grade you want._\n",
    "\n",
    "\n",
    "### Bonus assignments\n",
    "\n",
    "As a bonus assignment (no points, just swag), consider implementing Batch Normalization ([guide](https://gab41.lab41.org/batch-normalization-what-the-hey-d480039a9e3b)) or Dropout ([guide](https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5)). Note, however, that those \"layers\" behave differently when training and when predicting on test set.\n",
    "\n",
    "* Dropout:\n",
    "  * During training: drop units randomly with probability __p__ and multiply everything by __1/(1-p)__\n",
    "  * During final predicton: do nothing; pretend there's no dropout\n",
    "  \n",
    "* Batch normalization\n",
    "  * During training, it substracts mean-over-batch and divides by std-over-batch and updates mean and variance.\n",
    "  * During final prediction, it uses accumulated mean and variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1\n",
    "Xavier initialization\n",
    "\n",
    "We have just seen how a network works, but it was too shallow. I will first implement a layer with Xavier initialisation following the Glorot-Bengio formulation [here](http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization)\n",
    "\n",
    "$Var(W_i)=\\frac {2}{n_{in}}$ or\n",
    "\n",
    "$Var(W_i)=\\frac {2}{n_{in}+n_{out}}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseXavier(Layer):\n",
    "    def __init__(self, input_units, output_units, learning_rate=0.1,xavier_o=False):\n",
    "        \"\"\"\n",
    "        A dense layer is a layer which performs a learned affine transformation:\n",
    "        f(x) = <W*x> + b\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # initialize weights with small random numbers. We use normal initialization, \n",
    "        # but surely there is something better. Try this once you got it working: http://bit.ly/2vTlmaJ\n",
    "        #Truncate to avoid dead relus\n",
    "        if xavier_o:\n",
    "            x_var=np.sqrt(2/(input_units+output_units))\n",
    "        else:\n",
    "            x_var=np.sqrt(2/(input_units))\n",
    "        self.weights = np.random.randn(input_units, output_units)*x_var\n",
    "        self.biases = np.zeros(output_units)\n",
    "        \n",
    "    def forward(self,input):\n",
    "        \"\"\"\n",
    "        Perform an affine transformation:\n",
    "        f(x) = <W*x> + b\n",
    "        \n",
    "        input shape: [batch, input_units]\n",
    "        output shape: [batch, output units]\n",
    "        \"\"\"\n",
    "        return np.dot(input,self.weights)+self.biases\n",
    "    \n",
    "    def backward(self,input,grad_output,verbose=False):\n",
    "  \n",
    "        # compute d f / d x = d f / d dense * d dense / d x\n",
    "        # where d dense/ d x = weights transposed\n",
    "\n",
    "       \n",
    "        grad_input=np.dot(grad_output,self.weights.transpose())\n",
    "        \n",
    "        if verbose:\n",
    "            print(grad_output.shape)\n",
    "            print(self.weights.shape)\n",
    "            print(\"grad input\",grad_input.shape)\n",
    "            print(\"input\",input.shape)\n",
    "        \n",
    "        # compute gradient w.r.t. weights and biases\n",
    "        #This is df / dW =  df/DDense*dDense/dW \n",
    "        #dDense/dW=input.transposed()\n",
    "        #df/dW has dimensions of [input,output]\n",
    "        #df/dDDense has dimensions of [batch,output]\n",
    "        #dDense/dW has dims of [input,output]\n",
    "      \n",
    "        grad_biases = grad_output.mean(axis=0)\n",
    "   \n",
    "        dfddense=grad_output\n",
    "      \n",
    "        ddensedw=input.transpose()\n",
    "        grad_weights=np.dot(ddensedw,dfddense)/input.shape[0]        \n",
    "        \n",
    "               \n",
    "        assert grad_weights.shape == self.weights.shape and grad_biases.shape == self.biases.shape\n",
    "        # Here we perform a stochastic gradient descent step. \n",
    "        # Later on, you can try replacing that with something better.\n",
    "        self.weights = self.weights - self.learning_rate*grad_weights\n",
    "        self.biases = self.biases - self.learning_rate*grad_biases\n",
    "        \n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define three deep nets, and will train them in parallel to see what happens.\n",
    "\n",
    "All of them have five layers, the first one uses the default initialization with std 0.01, the second one uses the first formulation of Xavier initialisation, just taking into account the number of input units. The third one uses both the number of input and output units to initialise the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NEURONS=50\n",
    "LRATE=0.1\n",
    "network_basic=[]\n",
    "#Layer 1\n",
    "network_basic.append(Dense(X_train.shape[1],N_NEURONS,learning_rate=LRATE))\n",
    "network_basic.append(ReLU())\n",
    "#Layer2\n",
    "network_basic.append(Dense(N_NEURONS,N_NEURONS,learning_rate=LRATE))\n",
    "network_basic.append(ReLU())\n",
    "#Layer3\n",
    "network_basic.append(Dense(N_NEURONS,N_NEURONS,learning_rate=LRATE))\n",
    "network_basic.append(ReLU())\n",
    "#Layer4\n",
    "network_basic.append(Dense(N_NEURONS,N_NEURONS,learning_rate=LRATE))\n",
    "network_basic.append(ReLU())\n",
    "#Layer 5\n",
    "network_basic.append(Dense(N_NEURONS,10,learning_rate=LRATE))\n",
    "\n",
    "network_xavier=[]\n",
    "#Layer 1\n",
    "network_xavier.append(DenseXavier(X_train.shape[1],N_NEURONS,learning_rate=LRATE))\n",
    "network_xavier.append(ReLU())\n",
    "#Layer2\n",
    "network_xavier.append(DenseXavier(N_NEURONS,N_NEURONS,learning_rate=LRATE))\n",
    "network_xavier.append(ReLU())\n",
    "#Layer3\n",
    "network_xavier.append(DenseXavier(N_NEURONS,N_NEURONS,learning_rate=LRATE))\n",
    "network_xavier.append(ReLU())\n",
    "#Layer4\n",
    "network_xavier.append(DenseXavier(N_NEURONS,N_NEURONS,learning_rate=LRATE))\n",
    "network_xavier.append(ReLU())\n",
    "#Layer 5\n",
    "network_xavier.append(DenseXavier(N_NEURONS,10,learning_rate=LRATE))\n",
    "\n",
    "network_xavier2=[]\n",
    "#Layer 1\n",
    "network_xavier2.append(DenseXavier(X_train.shape[1],N_NEURONS,learning_rate=LRATE,xavier_o=True))\n",
    "network_xavier2.append(ReLU())\n",
    "#Layer2\n",
    "network_xavier2.append(DenseXavier(N_NEURONS,N_NEURONS,learning_rate=LRATE,xavier_o=True))\n",
    "network_xavier2.append(ReLU())\n",
    "#Layer3\n",
    "network_xavier2.append(DenseXavier(N_NEURONS,N_NEURONS,learning_rate=LRATE,xavier_o=True))\n",
    "network_xavier2.append(ReLU())\n",
    "#Layer4\n",
    "network_xavier2.append(DenseXavier(N_NEURONS,N_NEURONS,learning_rate=LRATE,xavier_o=True))\n",
    "network_xavier2.append(ReLU())\n",
    "#Layer 5\n",
    "network_xavier2.append(DenseXavier(N_NEURONS,10,learning_rate=LRATE,xavier_o=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(len(inputs))\n",
    "    for start_idx in trange(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "train_log_basic = []\n",
    "val_log_basic = []\n",
    "\n",
    "train_log_xavier = []\n",
    "val_log_xavier = []\n",
    "\n",
    "train_log_xavier2 = []\n",
    "val_log_xavier2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train accuracy(Basic): 0.09936 | Train accuracy(Xavier) 0.96532 | Train accuracy(Xavier2) 0.9651 |\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAFpCAYAAACfyu4TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGIwlSZIkwGAsSZIkAfD/A59Bhkj7qxOeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc96077a278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 2147/3125 [00:12<00:05, 171.83it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-951439b83f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_basic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_xavier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_xavier2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-bd507f901b0a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(network, X, y)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-c4557176dd37>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, input, grad_output, verbose)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mddensedw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mgrad_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddensedw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdfddense\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(25):\n",
    "\n",
    "        for x_batch,y_batch in iterate_minibatches(X_train,y_train,batchsize=16,shuffle=True):\n",
    "            train(network_basic,x_batch,y_batch)\n",
    "            train(network_xavier,x_batch,y_batch)\n",
    "            train(network_xavier2,x_batch,y_batch)\n",
    "\n",
    "        train_log_basic.append(np.mean(predict(network_basic,X_train)==y_train))\n",
    "        val_log_basic.append(np.mean(predict(network_basic,X_val)==y_val))\n",
    "        \n",
    "        train_log_xavier.append(np.mean(predict(network_xavier,X_train)==y_train))\n",
    "        val_log_xavier.append(np.mean(predict(network_xavier,X_val)==y_val))\n",
    "        \n",
    "        train_log_xavier2.append(np.mean(predict(network_xavier2,X_train)==y_train))\n",
    "        val_log_xavier2.append(np.mean(predict(network_xavier2,X_val)==y_val))\n",
    "\n",
    "        clear_output()\n",
    "        print(\"Epoch\",epoch)\n",
    "        print(\"Train accuracy(Basic):\",train_log_basic[-1],\"|\",\n",
    "              \"Train accuracy(Xavier)\",train_log_xavier[-1],\"|\",\n",
    "              \"Train accuracy(Xavier2)\",train_log_xavier2[-1],\"|\"\n",
    "             )\n",
    "        #print(\"Val accuracy(Xasic):\",val_log_basic[-1],\"Train accuracy(Xavier)\",train_log_basic[-1])\n",
    "        plt.figure(figsize=(12,6))\n",
    "        #plt.plot(train_log_basic,label='train accuracy (Classic)',color=\"red\")\n",
    "        plt.plot(val_log_basic,label='val accuracy (Classic)',color=\"#fe8181\",marker=\"*\")\n",
    "        \n",
    "        #plt.plot(train_log_xavier,label='train accuracy (Xavier)',color=\"blue\")\n",
    "        plt.plot(val_log_xavier,label='val accuracy (Xavier)',color=\"#99ccff\",marker=\"*\")\n",
    "        \n",
    "        plt.plot(val_log_xavier2,label='val accuracy (Xavier2)',color=\"#469280\",marker=\"*\")\n",
    "        \n",
    "        plt.legend(loc='best')\n",
    "        plt.grid()    \n",
    " \n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, it would be necessary to conduct several tests and average, due to the stochastic nature of training neural nets. Here, however, it becomes quite clear that Xavier initialisation provides a massive boost to the training. In this particular case, with the same learning rate and network architecture, the Xavier nets are already at >0.6 in accuracy after the first pass, while the classic network takes a very long time to get better. \n",
    "\n",
    "This is because even though the network has the capacity to be as good as the xavier nets, the gradients are not being propagated adequately through the net.\n",
    "\n",
    "Note that the Xavier network, even though it has more capacity than our previous network, was not able to go above 0.97. Perhaps using momentum or other technique would help in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described by Szegedy et al. [here](https://arxiv.org/pdf/1502.03167.pdf) .\n",
    "\n",
    "We start by definig a batchnorm class.\n",
    "\n",
    "I will initialise $\\gamma=1$, $\\beta=0$, and $m=0.99$ (for the moving average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(Layer):\n",
    "    def __init__(self,n_input, learning_rate=0.1):\n",
    "        \"\"\"A BatchNorm layer. It normalises the outputs in such a way\n",
    "        so that there is no distribution shift between layers\"\"\"\n",
    "        self.gamma=np.ones((1,n_input))\n",
    "        self.beta=np.zeros((1,n_input))\n",
    "        self.m=0.99\n",
    "        self.eps=0.001\n",
    "        self.learning_rate=learning_rate\n",
    "        self.mu_w=None\n",
    "        self.var_w=None\n",
    "        \n",
    "    \n",
    "    def forward(self, input, predict = False):\n",
    "        \"\"\"Apply elementwise batchnorm to [batch, input_units] matrix\n",
    "        As we go, take a rolling mean of mu and var.\n",
    "        Use those for prediction\"\"\"\n",
    "        if predict:\n",
    "            m=input.shape[0]\n",
    "            mub=self.mu_w\n",
    "            varb=self.var_w*(m/(m-1))\n",
    "            y1=self.gamma/np.sqrt(varb+self.eps)*input\n",
    "            y2=(self.beta-self.gamma*mub/np.sqrt(varb+self.eps))\n",
    "            return y1+y2\n",
    "        else:\n",
    "            mub=np.mean(input,axis=0,keepdims=True)\n",
    "            varb=np.var(input,axis=0,keepdims=True) \n",
    "            if self.mu_w is None or self.var_w is None:\n",
    "                self.mu_w = mub\n",
    "                self.var_w = varb\n",
    "            else:\n",
    "                self.mu_w=self.m*self.mu_w+(1-self.m)*mub\n",
    "                self.var_w=self.m*self.var_w+(1-self.m)*varb\n",
    "            \n",
    "        xhat= (input-mub)/np.sqrt(varb+self.eps)\n",
    "        return self.gamma*xhat+self.beta\n",
    "\n",
    "    \n",
    "    def backward(self, input, grad_output):\n",
    "        \"\"\"Compute gradient of loss w.r.t. batchnorm input\"\"\"\n",
    "        \n",
    "        mub=np.mean(input,axis=0,keepdims=True)\n",
    "        varb=np.var(input,axis=0,keepdims=True)\n",
    "        xhat= (input-mub)/np.sqrt(varb+self.eps)\n",
    "        m=input.shape[0]\n",
    "\n",
    "        #As a reminder, grad_output is dl/doutput\n",
    "        #grad_input is dl/dinput=dl/dlayer*dlayer/dinput\n",
    "        \n",
    "        #grad_dhat=dl/doutput times gamma\n",
    "        grad_xhat=self.gamma*grad_output \n",
    "        \n",
    "        assert grad_xhat.shape == grad_output.shape\n",
    "        \n",
    "        #grad_var is explained in the paper\n",
    "        k=-0.5*(varb+self.eps)**(-3/2)\n",
    "        \n",
    "        \n",
    "        grad_var=np.sum(grad_xhat*(input-mub),axis=0,keepdims=True)*k\n",
    "        \n",
    "        assert grad_var.shape == varb.shape\n",
    "        \n",
    "        #grad_mu is explained in the paper\n",
    "        k2=-1/np.sqrt(varb+self.eps)\n",
    "        grad_mu1=np.sum(grad_xhat*k2,axis=0,keepdims=True)\n",
    "        grad_mu2=grad_var*(-2*np.sum(input-mub,axis=0,keepdims=True))/m\n",
    "        grad_mu=grad_mu1+grad_mu2\n",
    "        \n",
    "        assert grad_mu.shape == mub.shape\n",
    "        \n",
    "        #grad_gamma=dot of dl/doutput imes xhat        \n",
    "        grad_gamma=np.mean(grad_output*xhat,axis=0,keepdims=True)\n",
    "        \n",
    "        #grad_beta = sum of dl/doutput\n",
    "        grad_beta=np.mean(grad_output,axis=0,keepdims=True)\n",
    "        \n",
    "        #grad_input is explained in the paper\n",
    "       \n",
    "        grad_input1=-k2*grad_xhat\n",
    "        grad_input2=grad_var*(2/m)*(input-mub)\n",
    "        grad_input3=grad_mu/m\n",
    "        grad_input=grad_input1+grad_input2+grad_input3\n",
    "        \n",
    "        assert grad_input.shape == input.shape\n",
    "        \n",
    "        assert grad_output.shape == grad_input.shape\n",
    "\n",
    "\n",
    "        # Here we perform a stochastic gradient descent step. \n",
    "        # Later on, you can try replacing that with something better.\n",
    "        self.gamma = self.gamma - self.learning_rate*grad_gamma\n",
    "        self.beta = self.beta - self.learning_rate*grad_beta       \n",
    "        \n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have to redefine forward and predict to account for a layer that behaves differently. I could also redefine the classes to take an extra parameter, but life's too short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▊   | 2147/3125 [00:30<00:13, 71.47it/s] "
     ]
    }
   ],
   "source": [
    "def forward(network, X, predict=False):\n",
    "    \"\"\"\n",
    "    Compute activations of all network layers by applying them sequentially.\n",
    "    Return a list of activations for each layer. \n",
    "    Make sure last activation corresponds to network logits.\n",
    "    \"\"\"\n",
    "    activations = []\n",
    "    input = X\n",
    " \n",
    "    for i,layer in enumerate(network):\n",
    "        if i==0:\n",
    "            if layer.__class__.__name__==\"BatchNorm\":\n",
    "                activations.append(layer.forward(input,predict))\n",
    "            else:\n",
    "                activations.append(layer.forward(input))\n",
    "        else:\n",
    "            if layer.__class__.__name__==\"BatchNorm\":\n",
    "                activations.append(layer.forward(activations[i-1],predict)) \n",
    "            else:\n",
    "                activations.append(layer.forward(activations[i-1]))           \n",
    "\n",
    "\n",
    "    x=np.zeros_like(activations[-1])\n",
    "    x[activations[-1]==np.amax(activations[-1],axis=1,keepdims=True)]=1\n",
    "    \n",
    "    assert len(activations) == len(network)\n",
    "    return activations\n",
    "\n",
    "def predict(network,X):\n",
    "    \"\"\"\n",
    "    Compute network predictions.\n",
    "    \"\"\"\n",
    "    logits = forward(network,X,predict=True)[-1]\n",
    "    return logits.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests for batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.50466564 -2.24158042  2.8326878  -2.450613  ]\n",
      " [ 0.50466564  4.12079021  2.8326878   4.57667069]\n",
      " [ 0.50466564 -0.12079021 -3.7098592  -0.10818511]\n",
      " [ 0.50466564  6.24158042  5.2117958   5.74788463]\n",
      " [ 7.98133744  2.          2.8326878   2.23424279]]\n",
      "Mean  [ 2.  2.  2.  2.]\n",
      "Var  [ 8.94409938  8.99550225  8.99964624  8.99862826]\n"
     ]
    }
   ],
   "source": [
    "#Forward\n",
    "bn=BatchNorm(n_input=4)\n",
    "\n",
    "MEAN=2\n",
    "STD=3\n",
    "bn.beta=MEAN\n",
    "bn.gamma=STD\n",
    "\n",
    "test_batch=np.array([[1,0,1,-1],\n",
    "                     [1,3,1,5],\n",
    "                     [1,1,-10,1],\n",
    "                     [1,4,5,6],\n",
    "                     [2,2,1,3]])\n",
    "output=bn.forward(test_batch)\n",
    "print(output)\n",
    "print(\"Mean \",np.mean(output,axis=0))\n",
    "print(\"Var \",np.var(output,axis=0))\n",
    "\n",
    "assert np.allclose(np.var(output,axis=0),STD*STD,rtol=1e-2)\n",
    "assert np.allclose(np.mean(output,axis=0),MEAN,rtol=1e-2)\n",
    "assert output.shape==test_batch.shape\n",
    "assert np.mean(output,axis=0).shape==(test_batch.shape[1],)\n",
    "assert np.var(output,axis=0).shape==(test_batch.shape[1],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 11)\n",
      "(10, 11)\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# To test the grads, we use gradients obtained via finite differences\n",
    "\n",
    "from util import eval_numerical_gradient\n",
    "\n",
    "N= 11\n",
    "x = np.linspace(-1,1,10*N).reshape([10,N])\n",
    "l = BatchNorm(n_input=N)\n",
    "l.beta=2\n",
    "l.gamma=7\n",
    "\n",
    "numeric_grads = eval_numerical_gradient(lambda x: l.forward(x).sum(),x)\n",
    "grads = l.backward(x,np.ones([10,N]))\n",
    "print(numeric_grads.shape)\n",
    "print(grads.shape)\n",
    "try:\n",
    "    assert np.allclose(grads,numeric_grads,rtol=1e-4,atol=1e-3)\n",
    "except:    \n",
    "    raise AssertionError(\"input gradient does not match numeric grad\")\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32) (1, 32)\n",
      "(1, 32) (1, 32)\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# Test the gradients w.r.t. params\n",
    "def compute_out_given_wb(gamma,beta):\n",
    "    l = BatchNorm(n_input=32,learning_rate=1)\n",
    "    l.gamma = gamma\n",
    "    l.beta = beta\n",
    "    x = np.linspace(-1,1,10*32).reshape([10,32])\n",
    "    return l.forward(x)\n",
    "    \n",
    "def compute_grad_by_params(gamma,beta):\n",
    "    l = BatchNorm(n_input=32,learning_rate=1)\n",
    "    l.gamma = gamma\n",
    "    l.beta = beta\n",
    "    x = np.linspace(-1,1,10*32).reshape([10,32])\n",
    "    l.backward(x,np.ones([10,32]))\n",
    "    return gamma - l.gamma, beta - l.beta\n",
    "    \n",
    "beta, gamma = 2+np.zeros((1,32)),3*np.ones((1,32))\n",
    "\n",
    "numeric_dw = eval_numerical_gradient(lambda gamma: compute_out_given_wb(gamma,beta).mean(0).sum(),gamma )\n",
    "numeric_db = eval_numerical_gradient(lambda beta: compute_out_given_wb(gamma,beta).mean(0).sum(),beta )\n",
    "grad_gamma,grad_beta = compute_grad_by_params(gamma,beta)\n",
    "print(numeric_dw.shape,grad_gamma.shape)\n",
    "print(numeric_db.shape,grad_beta.shape)\n",
    "print(numeric_dw-grad_gamma)\n",
    "print(numeric_db)\n",
    "print(grad_beta)\n",
    "assert np.allclose(numeric_dw,grad_gamma,rtol=1e-3,atol=1e-3), \"weight gradient does not match numeric weight gradient\"\n",
    "assert np.allclose(numeric_db,grad_beta,rtol=1e-3,atol=1e-3), \"weight gradient does not match numeric weight gradient\"\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test batchnorm vs a baseline network to see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NEURONS=50\n",
    "LRATE=0.1\n",
    "network_base=[]\n",
    "#Layer 1\n",
    "network_base.append(DenseXavier(X_train.shape[1],N_NEURONS,learning_rate=LRATE))\n",
    "network_base.append(ReLU())\n",
    "#Layer2\n",
    "network_base.append(DenseXavier(N_NEURONS,N_NEURONS,learning_rate=LRATE))\n",
    "network_base.append(ReLU())\n",
    "#Layer3\n",
    "network_base.append(DenseXavier(N_NEURONS,N_NEURONS,learning_rate=LRATE))\n",
    "network_base.append(ReLU())\n",
    "#Layer4\n",
    "network_base.append(DenseXavier(N_NEURONS,N_NEURONS,learning_rate=LRATE))\n",
    "network_base.append(ReLU())\n",
    "#Layer 5\n",
    "network_base.append(DenseXavier(N_NEURONS,10,learning_rate=LRATE))\n",
    "\n",
    "network_bn=[]\n",
    "#Layer 1\n",
    "network_bn.append(DenseXavier(X_train.shape[1],N_NEURONS,learning_rate=LRATE))\n",
    "network_bn.append(ReLU())\n",
    "network_bn.append(BatchNorm(N_NEURONS,learning_rate=LRATE))\n",
    "#Layer2\n",
    "network_bn.append(DenseXavier(N_NEURONS,N_NEURONS,learning_rate=LRATE))\n",
    "network_bn.append(ReLU())\n",
    "network_bn.append(BatchNorm(N_NEURONS,learning_rate=LRATE))\n",
    "#Layer3\n",
    "network_bn.append(DenseXavier(N_NEURONS,N_NEURONS,learning_rate=LRATE))\n",
    "network_bn.append(ReLU())\n",
    "network_bn.append(BatchNorm(N_NEURONS,learning_rate=LRATE))\n",
    "#Layer4\n",
    "network_bn.append(DenseXavier(N_NEURONS,N_NEURONS,learning_rate=LRATE))\n",
    "network_bn.append(ReLU())\n",
    "network_bn.append(BatchNorm(N_NEURONS,learning_rate=LRATE))\n",
    "#Layer 5\n",
    "network_bn.append(DenseXavier(N_NEURONS,10,learning_rate=LRATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(len(inputs))\n",
    "    for start_idx in trange(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "from IPython.display import clear_output\n",
    "\n",
    "train_log_base = []\n",
    "val_log_base = []\n",
    "\n",
    "train_log_bn = []\n",
    "val_log_bn = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11\n",
      "Train accuracy (base): 0.98166\n",
      "Train accuracy (bn): 0.98176\n",
      "Val accuracy (base): 0.9683\n",
      "Val accuracy (bn): 0.9733\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc9605f0780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1014/3125 [00:08<00:16, 125.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-8cf6e74e36d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_bn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_base\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtrain_log_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_base\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-bd507f901b0a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(network, X, y)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-c4557176dd37>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, input, grad_output, verbose)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mgrad_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(150):\n",
    "\n",
    "        for x_batch,y_batch in iterate_minibatches(X_train,y_train,batchsize=16,shuffle=True):\n",
    "            train(network_bn,x_batch,y_batch)\n",
    "            train(network_base,x_batch,y_batch)\n",
    "\n",
    "        train_log_base.append(np.mean(predict(network_base,X_train)==y_train))\n",
    "        val_log_base.append(np.mean(predict(network_base,X_val)==y_val))\n",
    "        \n",
    "        train_log_bn.append(np.mean(predict(network_bn,X_train)==y_train))\n",
    "        val_log_bn.append(np.mean(predict(network_bn,X_val)==y_val))\n",
    "\n",
    "        clear_output()\n",
    "        print(\"Epoch\",epoch)\n",
    "        print(\"Train accuracy (base):\",train_log_base[-1])\n",
    "        print(\"Train accuracy (bn):\",train_log_bn[-1])\n",
    "        print(\"Val accuracy (base):\",val_log_base[-1])\n",
    "        print(\"Val accuracy (bn):\",val_log_bn[-1])\n",
    "        \n",
    "        plt.plot(val_log_base,label='val accuracy (base)')\n",
    "        plt.plot(val_log_bn,label='val accuracy (bn)')\n",
    "        plt.plot(train_log_base,label='train accuracy (base)')\n",
    "        plt.plot(train_log_bn,label='train accuracy (bn)')\n",
    "        plt.legend(loc='best')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that batchnorm initially converges faster, and the variance in its trace is much smaller than the baseline. However, the baseline outperforms batchnorm after enough iterations. I suspect my implementation of batchnorm is not correct, but I can't figure out why."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "264px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
